{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Script for Text OCR using OpenAI API\n",
    "---\n",
    "[OpenAI API documentation](https://platform.openai.com/docs/api-reference/introduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv # load .env file for obtaining api key\n",
    "from openai import OpenAI      # text generation\n",
    "import pandas as pd            # save generated text as csv\n",
    "import re                      # regex for cleaning text\n",
    "import random      \n",
    "\n",
    "load_dotenv()  # config .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "\n",
    "def generate_OCR_text_shopping(given_text, max_tokens = 6):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"Output something that is found in a store from the given broad category. I just want the item name, \n",
    "            be thorough with your output.\"\"\"\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Given shopping category: {given_text}\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=1\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def generate_OCR_text_food_dishes(given_text, max_tokens = 6):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\"Your job is just to output me a some food or dish name from a broad food/dish category that I will provide.\"\"\"\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Given food/dish category: {given_text}\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=1\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "def generate_OCR_text_titles(given_text, max_tokens = 12):\n",
    "    response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"\"\" Your job is just to output me a specific title from a broad type of medium category that I will provide.\n",
    "            This title can either be some famous title or a made up one pertaining to the given category. Try not to pick or make long \n",
    "            titles.\"\"\"\n",
    "        },\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Given medium category: {given_text}\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=max_tokens,\n",
    "    top_p=1\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# functions used to clean up the generated text (aka output)\n",
    "def remove_quotation_marks(response_output):\n",
    "    return response_output.replace('\"', '')\n",
    "\n",
    "def remove_delimiters(response_output):\n",
    "    response_output = response_output.replace('\\n', '')\n",
    "    response_output = response_output.replace('\\\\', '')\n",
    "    return response_output\n",
    "\n",
    "def clean_text(response_output, title=False):\n",
    "    # remove emojis (if any)\n",
    "    response_output = re.sub(r'[^\\w\\s,]', '', response_output)\n",
    "\n",
    "    # remove specific punctuation (in this case, a period)\n",
    "    response_output = response_output.replace('.', '')\n",
    "\n",
    "    # if not a title, convert text to lowercase\n",
    "    if not title:\n",
    "        response_output = response_output.lower()\n",
    "\n",
    "    return response_output\n",
    "\n",
    "# generation of 10,000 entries\n",
    "shopping_goods_entries = list()\n",
    "food_dishes_entries = list()\n",
    "medium_entries = list()\n",
    "\n",
    "duplicates = 0 # count of duplicates (just for documentation purposes)\n",
    "\n",
    "# categories for shopping, food and dishes, and title types\n",
    "shopping_goods_categories = [\n",
    "    \"Groceries\", \"Fresh Produce\", \"Dairy Products\", \"Bakery\", \"Meat and Poultry\",\n",
    "    \"Seafood\", \"Frozen Foods\", \"Canned Goods\", \"Snacks\", \"Sweets\",\n",
    "    \"Beverages\", \"Household Items\", \"Cleaning Supplies\", \"Laundry Supplies\", \"Kitchen Essentials\",\n",
    "    \"Skincare\", \"Haircare\", \"Oral Care\", \"Bath and Body\", \"Health and Wellness Products\", \"Clothing and Accessories\",\n",
    "    \"Men's Clothing\", \"Women's Clothing\", \"Children's Clothing\", \"Shoes\", \"Jewelry and Accessories\",\n",
    "    \"Electronics\", \"Televisions\", \"Computers and Laptops\", \"Mobile Phones\", \"Cameras\",\n",
    "    \"Audio Equipment\", \"Home and Furniture\", \"Living Room Furniture\", \"Bedroom Furniture\", \"Kitchen and Dining Furniture\",\n",
    "    \"Home DÃ©cor\", \"Bedding and Linens\", \"Toys\", \"Action Figures\", \"Board Games\",\n",
    "    \"Puzzles\", \"Outdoor Toys\", \"Automotive\", \"Car Maintenance Products\", \"Tires\",\n",
    "    \"Car Accessories\", \"Tools and Equipment\", \"Outdoor Equipment\", \"Sporting Goods\", \"Fitness Equipment\",\n",
    "    \"Outdoor Gear\", \"Bicycles\", \"Garden and Patio\", \"Gardening Tools\", \"Outdoor Furniture\",\n",
    "    \"Plants and Seeds\", \"Grills and Outdoor Cooking\", \"Pharmacy\", \"Prescription Medications\", \"Over-the-Counter Medications\",\n",
    "    \"Vitamins and Supplements\", \"Office Supplies\", \"Office Furniture\", \"School Supplies\", \"Pet Supplies\",\n",
    "    \"Pet Food\", \"Pet Toys\", \"Pet Health Products\", \"Pet Accessories\", \"Consoles\"\n",
    "]\n",
    "\n",
    "food_and_dishes_categories = [\n",
    "    \"Fruits\", \"Vegetables\", \"Dairy Products\", \"Meat and Poultry\", \"Seafood\",\n",
    "    \"Bakery\", \"Frozen Foods\", \"Canned Goods\", \"Beverages\", \"Grains and Pasta\",\n",
    "    \"Cereals\", \"Condiments and Sauces\", \"Spices and Herbs\", \"Nuts and Seeds\", \"Soups and Broths\",\n",
    "    \"Oils and Vinegars\", \"Health Foods\", \"Baby Food\", \"Breakfast Foods\", \"Mexican Dishes\",\n",
    "    \"American Dishes\", \"Argentinian Dishes\", \"Indian Dishes\", \"Chinese Dishes\", \"Japanese Dishes\",\n",
    "    \"Italian Dishes\", \"French Dishes\", \"German Dishes\", \"Greek Dishes\", \"Korean Dishes\",\n",
    "    \"Thai Dishes\", \"Vietnamese Dishes\", \"Spanish Dishes\", \"Brazilian Dishes\", \"Middle Eastern Dishes\",\n",
    "    \"African Dishes\", \"Caribbean Dishes\", \"Deli Meats\", \"Cheese\", \"Ice Cream and Desserts\"\n",
    "]\n",
    "\n",
    "medium_types = [\n",
    "    \"Books\", \"Movies\", \"TV Shows\", \"Songs\", \"Albums\",\n",
    "    \"Paintings\", \"Poems\", \"Plays\", \"Video Games\", \"Podcasts\",\n",
    "    \"Websites\", \"Magazines\", \"Academic Journals\", \"Newspapers\", \"Comics\"\n",
    "]\n",
    "\n",
    "\n",
    "while len(shopping_goods_entries) < 5000:\n",
    "    # randomly choose a category\n",
    "    shopping_goods_category = random.choice(shopping_goods_categories)\n",
    "    output = generate_OCR_text_shopping(shopping_goods_category)\n",
    "\n",
    "    # clean up the output\n",
    "    output = remove_quotation_marks(output)\n",
    "    output = remove_delimiters(output)\n",
    "    output = clean_text(output)\n",
    "\n",
    "    # make sure we don't have duplicates\n",
    "    if output not in shopping_goods_entries:\n",
    "        shopping_goods_entries.append(output)\n",
    "    else:\n",
    "        duplicates += 1\n",
    "\n",
    "while len(food_dishes_entries) < 2500:\n",
    "    # randomly choose a category\n",
    "    food_dish_category = random.choice(food_and_dishes_categories)\n",
    "    output = generate_OCR_text_food_dishes(food_dish_category)\n",
    "\n",
    "    # clean up the output\n",
    "    output = remove_quotation_marks(output)\n",
    "    output = remove_delimiters(output)\n",
    "    output = clean_text(output)\n",
    "\n",
    "    # make sure we don't have duplicates\n",
    "    if output not in food_dishes_entries and shopping_goods_entries:\n",
    "        food_dishes_entries.append(output)\n",
    "    else:\n",
    "        duplicates += 1\n",
    "    \n",
    "while len(medium_entries) < 2500:\n",
    "    # randomly choose a category\n",
    "    medium_category = random.choice(medium_types)\n",
    "    output = generate_OCR_text_titles(medium_category)\n",
    "\n",
    "    # clean up the output\n",
    "    output = remove_quotation_marks(output)\n",
    "    output = remove_delimiters(output)\n",
    "    output = clean_text(output, title=True)\n",
    "\n",
    "    # make sure we don't have duplicates\n",
    "    if output not in medium_entries:\n",
    "        medium_entries.append(output)\n",
    "    else:\n",
    "        duplicates += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shopping Good Entries (size: 50):\n",
      "['allseason tires', 'mozzarella cheese', 'transformers action figures', 'apple iphone 13 pro max', 'mountain bike', 'desk chair', 'lego star wars millennium falcon', '65inch 4k smart', 'greek yogurt', 'garden benches', 'blouse', 'iphone 13', 'running shoes', 'queensized platform bed frame', 'pain reliever  for', 'kingsize platform bed', 'duvet cover', 'marvel legends series action figures', 'laundry detergent', 'gold necklace with a heartshaped', 'chocolatecovered almonds', 'laptop stand', 'engine oil', 'strawberries', 'maxi dress', 'multivitamins', 'shampoo', 'candle holders', 'chunkystyle chicken noodle', 'frozen pizza', 'leather jacket', 'sneakers', 'item found in a pharmacy', 'interactive treatdispensing toy', 'outdoor dining set', 'stainless steel pots and pans', 'toothpaste', 'blue jeans', 'transformers action figure', 'pain relief medication', 'flea and tick medication', 'jigsaw puzzle', 'jelly beans', 'wooden picture frames', 'milk', 'pillowcases', 'smart tv with 4k', 'bed frame', 'vitamin d3 supplements', 'croissants']\n",
      "\n",
      "\n",
      "Food and Dishes Entries (size: 25):\n",
      "['egg benedict', 'lobster bisque', 'yogurt', 'pad thai', 'bibimbap', 'pastrami', 'roasted brussels sprouts', 'moussaka', 'mozzarella cheese', 'feijoada', 'cuminspiced grilled chicken', 'macaroni and cheese', 'ice cream', 'empanadas', 'cheeseburger', 'minestrone soup', 'tuna salad', 'lasagna', 'chocolate lava cake', 'hummus', 'ratatouille', 'fufu and egusi', 'jollof rice', 'steak and mashed potatoes', 'asado']\n",
      "\n",
      "\n",
      "Medium Entries (size: 25):\n",
      "['Title The Adventures of Captain Comet', 'Journal of Applied Psychology', 'Title The Legend of Zelda Breath of the Wild', 'Title The Daily Feed', 'Thriller', 'Bohemian Rhapsody', 'The Raven', 'Starry Night by Vincent van Gogh', 'The Daily News', 'Title Serial', 'The Daily Gazette', 'The Road Not Taken', 'Title A Streetcar Named Desire', 'Title The Amazing SpiderMan', 'Title Bohemian Rhapsody', 'Title Fashionista Monthly', 'Famous title Romeo and Juliet', 'Title True Crime Chronicles', 'The Shawshank Redemption', 'Title Legend of Zelda Breath of the Wild', 'Google', 'Title Glamour', 'Starry Night', 'Serial', 'Album Title Thriller']\n",
      "\n",
      "\n",
      "Number of duplicates: 23\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shopping Good Entries (size: {len(shopping_goods_entries)}):\")\n",
    "print(shopping_goods_entries)\n",
    "print('\\n')\n",
    "\n",
    "print(f\"Food and Dishes Entries (size: {len(food_dishes_entries)}):\")\n",
    "print(food_dishes_entries)\n",
    "print('\\n')\n",
    "\n",
    "print(f\"Medium Entries (size: {len(medium_entries)}):\")\n",
    "print(medium_entries)\n",
    "print('\\n')\n",
    "\n",
    "print(f\"Number of duplicates: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store in a pandas dataframe\n",
    "df = pd.DataFrame(entries, columns=['Words/Short Phrase'])\n",
    "\n",
    "# save as a csv file\n",
    "df.to_csv('OCR_text_dataset.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "summer-research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
